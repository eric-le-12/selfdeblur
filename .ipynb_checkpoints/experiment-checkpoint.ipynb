{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import layers\n",
    "from utils import non_local_dot_product as block\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    \"\"\"\n",
    "        https://arxiv.org/abs/1710.05941\n",
    "        The hype was so huge that I could not help but try it\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Swish, self).__init__()\n",
    "        self.s = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.s(x)\n",
    "\n",
    "\n",
    "def act(act_fun = 'LeakyReLU'):\n",
    "    '''\n",
    "        Either string defining an activation function or module (e.g. nn.ReLU)\n",
    "    '''\n",
    "    if isinstance(act_fun, str):\n",
    "        if act_fun == 'LeakyReLU':\n",
    "            return nn.LeakyReLU(0.2, inplace=True)\n",
    "        elif act_fun == 'Swish':\n",
    "            return Swish()\n",
    "        elif act_fun == 'ELU':\n",
    "            return nn.ELU()\n",
    "        elif act_fun == 'none':\n",
    "            return nn.Sequential()\n",
    "        else:\n",
    "            assert False\n",
    "    else:\n",
    "        return act_fun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Concat(nn.Module):\n",
    "    def __init__(self, dim, *args):\n",
    "        super(Concat, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "        for idx, module in enumerate(args):\n",
    "            self.add_module(str(idx), module)\n",
    "\n",
    "    def forward(self, input):\n",
    "        inputs = []\n",
    "        for module in self._modules.values():\n",
    "            inputs.append(module(input))\n",
    "\n",
    "        inputs_shapes2 = [x.shape[2] for x in inputs]\n",
    "        inputs_shapes3 = [x.shape[3] for x in inputs]        \n",
    "\n",
    "        if np.all(np.array(inputs_shapes2) == min(inputs_shapes2)) and np.all(np.array(inputs_shapes3) == min(inputs_shapes3)):\n",
    "            inputs_ = inputs\n",
    "        else:\n",
    "            target_shape2 = min(inputs_shapes2)\n",
    "            target_shape3 = min(inputs_shapes3)\n",
    "\n",
    "            inputs_ = []\n",
    "            for inp in inputs: \n",
    "                diff2 = (inp.size(2) - target_shape2) // 2 \n",
    "                diff3 = (inp.size(3) - target_shape3) // 2 \n",
    "                inputs_.append(inp[:, :, diff2: diff2 + target_shape2, diff3:diff3 + target_shape3])\n",
    "\n",
    "        return torch.cat(inputs_, dim=self.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skip(nn.Module):\n",
    "    \"\"\"\n",
    "    Construct a unet like model with skip connections\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_input_channels=2,\n",
    "        num_output_channels=3,\n",
    "        num_channels_down=[16, 32, 64, 128, 128],\n",
    "        num_channels_up=[16, 32, 64, 128, 128],\n",
    "        num_channels_skip=[4, 4, 4, 4, 4],\n",
    "        filter_size_down=3,\n",
    "        filter_size_up=3,\n",
    "        filter_skip_size=1,\n",
    "        need_sigmoid=True,\n",
    "        need_bias=True,\n",
    "        pad=\"zero\",\n",
    "        upsample_mode=\"nearest\",\n",
    "        downsample_mode=\"stride\",\n",
    "        act_fun=\"LeakyReLU\",\n",
    "        need1x1_up=True,\n",
    "    ):\n",
    "        super(Skip, self).__init__()\n",
    "        self.num_input_channels = num_input_channels\n",
    "        self.num_output_channels = num_output_channels\n",
    "        self.num_channels_down = num_channels_down\n",
    "        self.num_channels_up = num_channels_up\n",
    "        self.num_channels_skip = num_channels_skip\n",
    "        self.filter_size_up = filter_size_up\n",
    "        self.filter_size_down = filter_size_down\n",
    "        self.filter_skip_size = filter_skip_size\n",
    "        self.need_sigmoid = need_sigmoid\n",
    "        self.need_bias = need_bias\n",
    "        self.pad = pad\n",
    "        self.upsample_mode = upsample_mode\n",
    "        self.downsample_mode = downsample_mode\n",
    "        self.act_fun = act_fun\n",
    "        self.need1x1_up = need1x1_up\n",
    "\n",
    "    def single_skip(self,\n",
    "                    in_channels,\n",
    "                    num_channels_skip,\n",
    "                    filter_skip_size,\n",
    "                    pad,\n",
    "                    bias=True):\n",
    "        \"\"\"\n",
    "        implement a skip module:\n",
    "        receive N,C,H,W output N,Ck,H,W with filter size as filter_skip_size, padding method as pad\n",
    "        \"\"\"\n",
    "        skip = nn.Sequential()\n",
    "        padder = None\n",
    "        downsampler = None\n",
    "        # convolution module to decrease channels\n",
    "        ## padding size for conv2d\n",
    "        to_pad = int((filter_skip_size - 1) / 2)\n",
    "        ## choosing path method : zero or flection\n",
    "        if pad == \"reflection\":\n",
    "            padder = nn.ReflectionPad2d(to_pad)\n",
    "            to_pad = 0\n",
    "        ## constructing conv2d\n",
    "        conv2d = nn.Conv2d(\n",
    "            in_channels,\n",
    "            num_channels_skip,\n",
    "            filter_skip_size,\n",
    "            1,\n",
    "            padding=to_pad,\n",
    "            bias=bias,\n",
    "        )\n",
    "        ## leave only non -None layers\n",
    "        layers = filter(lambda x: x is not None, [padder, conv2d, downsampler])\n",
    "        ## downsampler if neccessary\n",
    "\n",
    "        skip.add_module(\"Skip_conv\", nn.Sequential(*layers))\n",
    "\n",
    "        # adding bn and activation\n",
    "        skip.add_module(\"Skip_BN\", nn.BatchNorm2d(num_channels_skip))\n",
    "        skip.add_module(\"Leaky_RELU\", act(act_fun=\"LeakyReLU\"))\n",
    "\n",
    "        return skip\n",
    "\n",
    "    def deeper_before_concat(\n",
    "        self,\n",
    "        in_channels,\n",
    "        num_channels_down,\n",
    "        filter_down_size,\n",
    "        stride,\n",
    "        pad,\n",
    "        downsampler,\n",
    "        bias,\n",
    "        act_fun,\n",
    "        non_local\n",
    "    ):\n",
    "        \"\"\"\n",
    "        con_block -> bn -> leaky relu -> nonlocal2D block ->...\n",
    "        purpose : reduce spatial dimension while increasing depth / num of channels\n",
    "\n",
    "        \"\"\"\n",
    "        before_concat = []\n",
    "        ## append conv : first block stride = 2 to reduce spatial dimensions\n",
    "        before_concat.append(\n",
    "            layers.conv(\n",
    "                in_channels,\n",
    "                num_channels_down,\n",
    "                filter_down_size,\n",
    "                stride=2,\n",
    "                bias=bias,\n",
    "                pad=pad,\n",
    "                downsample_mode=downsampler,\n",
    "            ))\n",
    "\n",
    "        before_concat.append(nn.BatchNorm2d(num_channels_down))\n",
    "        before_concat.append(layers.act(act_fun))\n",
    "        if (non_local):\n",
    "            before_concat.append(\n",
    "                block.NONLocalBlock2D(in_channels=num_channels_down))\n",
    "        \n",
    "        before_concat.append(\n",
    "            layers.conv(\n",
    "                num_channels_down,\n",
    "                num_channels_down,\n",
    "                filter_down_size,\n",
    "                bias=bias,\n",
    "                pad=pad,\n",
    "            ))\n",
    "        before_concat.append(nn.BatchNorm2d(num_channels_down))\n",
    "        before_concat.append(act(act_fun))\n",
    "        return nn.Sequential(*before_concat)\n",
    "\n",
    "    def construct(self):\n",
    "        # self.model = nn.Sequential()\n",
    "        # construct a model from input\n",
    "        depth = len(self.num_channels_down)\n",
    "        # useful for debug later\n",
    "        assert len(self.num_channels_up) == len(self.num_channels_down)\n",
    "        assert len(self.num_channels_down) == len(self.num_channels_skip)\n",
    "        assert len(self.num_channels_down) > 0\n",
    "        ### build a unet like module\n",
    "        encoder = [None]* depth\n",
    "        skip = [None]* depth\n",
    "        post = [None]* depth\n",
    "        decoder = [None] * depth\n",
    "        non_local = False\n",
    "        ### create module\n",
    "        for i in range(depth):\n",
    "            if (i == 0):\n",
    "                in_channels = self.num_input_channels\n",
    "                non_local = False\n",
    "            else:\n",
    "                in_channels = self.num_channels_down[i - 1]\n",
    "                if (i>1):\n",
    "                    non_local = True\n",
    "            encoder[i] = self.deeper_before_concat(in_channels,\n",
    "                                                   self.num_channels_down[i],\n",
    "                                                   self.filter_size_down,\n",
    "                                                   1, self.pad,\n",
    "                                                   self.downsample_mode, self.need_bias,\n",
    "                                                   self.act_fun,non_local)\n",
    "            skip[i] = self.single_skip(in_channels, self.num_channels_skip[i],\n",
    "                                       self.filter_skip_size, self.pad,\n",
    "                                       self.need_bias)\n",
    "            post[i] = self.post_processing(self.num_channels_down[i]+self.num_channels_skip[i],self.num_channels_up[i],self.filter_size_up)\n",
    "            # decoder[i] = nn.Sequential(torch.cat(skip[5-i],))\n",
    "        \n",
    "        \n",
    "        \n",
    "        return encoder, skip,post\n",
    "    \n",
    "    def post_processing(self,input_channel,output_channel,kernel_size):\n",
    "        \"\"\"\n",
    "        return post_processing layers\n",
    "        input channel : num of channels for coming input\n",
    "        output channel: desired number of channels\n",
    "        \"\"\"\n",
    "        bn = []\n",
    "        bn.append(nn.BatchNorm2d(input_channel))\n",
    "        bn.append(layers.conv(input_channel, output_channel, kernel_size, bias=self.need_bias, pad=self.pad))\n",
    "        bn.append(nn.BatchNorm2d(output_channel))\n",
    "        bn.append(act(self.act_fun))\n",
    "        bn.append(layers.conv(output_channel, output_channel, 1, bias=self.need_bias, pad=self.pad))\n",
    "        bn.append(nn.BatchNorm2d(output_channel))\n",
    "        bn.append(act(self.act_fun))\n",
    "        return bn\n",
    "        \n",
    "        \n",
    "    def model_tail(self):\n",
    "        \"\"\"\n",
    "        construct the tail of model\n",
    "        \"\"\"\n",
    "        tail = []\n",
    "        input_channel = self.num_channels_up[0]\n",
    "        output_channel = self.num_output_channels\n",
    "        kernel_size = 1\n",
    "\n",
    "        tail.append(layers.conv(input_channel, output_channel, kernel_size, bias=self.need_bias, pad=self.pad))\n",
    "        tail.append(nn.Sigmoid())\n",
    "        return tail\n",
    "\n",
    "    def forward(self, input):\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo =  Skip(num_input_channels=8,\n",
    "        num_output_channels=1,\n",
    "         num_channels_down = [128, 128, 128, 128, 128],\n",
    "        num_channels_up   = [128, 128, 128, 128, 128],\n",
    "        num_channels_skip = [16, 16, 16, 16, 16],\n",
    "        filter_size_down=3,\n",
    "        filter_size_up=3,\n",
    "        filter_skip_size=1,\n",
    "        need_sigmoid=True,\n",
    "        need_bias=True,\n",
    "        pad=\"reflection\",\n",
    "        upsample_mode=\"nearest\",\n",
    "        downsample_mode=\"stride\",\n",
    "        act_fun=\"LeakyReLU\",\n",
    "        need1x1_up=True)\n",
    "device = torch.device('cuda:0')\n",
    "demo = demo.to(device)\n",
    "e,s,p = demo.construct()\n",
    "print(len(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(s[0],(1,8,320,505))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "e[4].add_module(\"upsampling_2\",nn.Upsample(scale_factor=2, mode=\"nearest\"))\n",
    "\n",
    "deeper = nn.Sequential(Concat(1,s[4],e[4]))\n",
    "## add post-process layers\n",
    "for i in p[4]:\n",
    "    deeper.add(i)\n",
    "e[3].add_module(\"deeper_3\",deeper)\n",
    "## add upsampling\n",
    "e[3].add_module(\"upsampling_2\",nn.Upsample(scale_factor=2, mode=\"nearest\"))\n",
    "\n",
    "model = None\n",
    "deeper = nn.Sequential(Concat(1,s[3],e[3]))\n",
    "## add post-process layers\n",
    "for i in p[3]:\n",
    "    deeper.add(i)\n",
    "e[2].add_module(\"deeper_3\",deeper)\n",
    "e[2].add_module(\"upsampling_2\",nn.Upsample(scale_factor=2, mode=\"nearest\"))\n",
    "\n",
    "deeper = nn.Sequential(Concat(1,s[2],e[2]))\n",
    "## add post-process layers\n",
    "for i in p[2]:\n",
    "    deeper.add(i)\n",
    "e[1].add_module(\"deeper_3\",deeper)\n",
    "e[1].add_module(\"upsampling_2\",nn.Upsample(scale_factor=2, mode=\"nearest\"))\n",
    "\n",
    "deeper = nn.Sequential(Concat(1,s[1],e[1]))\n",
    "## add post-process layers\n",
    "for i in p[1]:\n",
    "    deeper.add(i)\n",
    "e[0].add_module(\"deeper_2\",deeper)\n",
    "e[0].add_module(\"upsampling_1\",nn.Upsample(scale_factor=2, mode=\"nearest\"))\n",
    "\n",
    "model = nn.Sequential(Concat(1,s[0],e[0]))\n",
    "## add post-process layers\n",
    "for i in p[0]:\n",
    "    model.add(i)\n",
    "\n",
    "for i in (demo.model_tail()):\n",
    "    print(i)\n",
    "    model.add(i)\n",
    "# ref.add_module(\"deeper_depth_2\",deeper)\n",
    "\n",
    "print(summary(model,(1,8,1278,2020),depth=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# e[4].add_module(\"upsampling_2\",nn.Upsample(scale_factor=2, mode=\"nearest\"))\n",
    "\n",
    "# deeper = nn.Sequential(Concat(1,s[4],e[4]))\n",
    "# ## add post-process layers\n",
    "# for i in p[4]:\n",
    "#     deeper.add(i)\n",
    "# e[3].add_module(\"deeper_3\",deeper)\n",
    "# ## add upsampling\n",
    "# e[3].add_module(\"upsampling_2\",nn.Upsample(scale_factor=2, mode=\"nearest\"))\n",
    "\n",
    "\n",
    "# model = None\n",
    "# deeper = nn.Sequential(Concat(1,s[3],e[3]))\n",
    "# ## add post-process layers\n",
    "# for i in p[3]:\n",
    "#     deeper.add(i)\n",
    "# e[2].add_module(\"deeper_3\",deeper)\n",
    "# e[2].add_module(\"upsampling_2\",nn.Upsample(scale_factor=2, mode=\"nearest\"))\n",
    "\n",
    "# deeper = nn.Sequential(Concat(1,s[2],e[2]))\n",
    "# e[1].add_module(\"deeper_3\",deeper)\n",
    "# e[1].add_module(\"upsampling_2\",nn.Upsample(scale_factor=2, mode=\"nearest\"))\n",
    "\n",
    "# deeper = nn.Sequential(Concat(1,s[1],e[1]))\n",
    "# e[0].add_module(\"deeper_2\",deeper)\n",
    "# e[0].add_module(\"upsampling_1\",nn.Upsample(scale_factor=2, mode=\"nearest\"))\n",
    "\n",
    "# model = nn.Sequential(Concat(1,s[0],e[0]))\n",
    "\n",
    "\n",
    "# for i in (demo.model_tail()):\n",
    "#     print(i)\n",
    "#     model.add(i)\n",
    "# # ref.add_module(\"deeper_depth_2\",deeper)\n",
    "\n",
    "# print(summary(model,(1,8,1278,2020),depth=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(demo.model_tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-robin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
